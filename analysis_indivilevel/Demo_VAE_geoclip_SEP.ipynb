{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from geoclip import LocationEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate mock_data_final for showing the process of generating prototypes, \n",
    "# The mock_data_final is used for simulating the real-scenario data that we used for training the SEP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(y):\n",
    "    # Count the frequency of each class\n",
    "    class_counts = torch.bincount(y)\n",
    "    # Calculate the total number of samples\n",
    "    total_samples = len(y)\n",
    "    # Number of classes is the length of class_counts\n",
    "    num_classes = len(class_counts)\n",
    "    # Calculate class weights\n",
    "    class_weights = total_samples / (class_counts * num_classes)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AUCPR(y_test, y_score, n_classes):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    area_pr = dict()\n",
    "    precision_mean=dict()\n",
    "    recall_mean=dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                            y_score[:, i])\n",
    "        area_pr[i]= auc(recall[i], precision[i],)\n",
    "        precision_mean[i]=precision[i].mean()\n",
    "        recall_mean[i]=recall[i].mean()\n",
    "        \n",
    "    mean_AUCPR = np.mean(list(area_pr.values()))\n",
    "    mean_precision = np.mean(list(precision_mean.values()))\n",
    "    mean_recall = np.mean(list(recall_mean.values()))\n",
    "    mean_f1=2 * (mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
    "    return mean_precision, mean_recall, mean_f1, mean_AUCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the VAE model\n",
    "class SAVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAVAE, self).__init__()\n",
    "        # Define the concatenation part\n",
    "        self.fc11 = nn.Linear(12, 64)\n",
    "        self.fc12 = nn.Linear(512, 64)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        # Define the second fully connected layer for mu\n",
    "        self.fc21 = nn.Linear(128, 16)\n",
    "        # Define the third fully connected layer for logvar\n",
    "        self.fc22 = nn.Linear(128, 16)\n",
    "        # Define the fourth fully connected layer for decoding\n",
    "        self.fc3 = nn.Linear(16, 12)\n",
    "        # Define the classifier layer\n",
    "        self.classifier = nn.Linear(16, 3)\n",
    "        self.LocEncoder = LocationEncoder()\n",
    "\n",
    "    # Define the encoder part of VAE\n",
    "    def encode(self, x_concat):\n",
    "        h1 = self.LeakyReLU(x_concat)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    # Define the reparameterization trick\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    # Define the decoder part of VAE\n",
    "    def decode(self, z):\n",
    "        h3=self.fc3(z)\n",
    "        return torch.sigmoid(h3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=x[:,2:]\n",
    "        x2=x[:,:2]\n",
    "        \n",
    "        loc_embed=self.LocEncoder(x2)\n",
    "        x_concat=torch.cat((self.fc12(loc_embed), self.fc11(x1)), dim=1)\n",
    "        mu, logvar = self.encode(x_concat.view(-1, x_concat.shape[1]))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # dimension of z is 16\n",
    "        # return the reconstructed x, the classifier output, mu and logvar\n",
    "        return self.decode(z), self.classifier(z), mu, logvar, z\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(recon_x, x1, mu, logvar, y, y_pred, class_weights):\n",
    "\n",
    "    # Calculate the Mean Squared Error loss\n",
    "    MSE = F.mse_loss(recon_x, x1, reduction='sum')\n",
    "    # Calculate the KL Divergence\n",
    "    KLD = beta_value*(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "    # Calculate the Cross Entropy loss\n",
    "    CE = F.cross_entropy(y_pred, y, weight=class_weights)\n",
    "    # The total loss is the sum of MSE, KLD, and CE\n",
    "    return MSE, KLD, CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train(train_loader, model, device):\n",
    "    model.train()\n",
    "    MSE = 0\n",
    "    KLD = 0\n",
    "    CE = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # This line is doing several things:\n",
    "        # 1. It's passing the input data through the model, which is an instance of the VAE class.\n",
    "        # 2. The model's forward method returns four values: the reconstructed batch (recon_batch), the predicted labels (y_pred), \n",
    "        #    and the mean (mu) and log variance (logvar) of the latent variables.\n",
    "        # 3. These four values are being unpacked into the variables recon_batch, y_pred, mu, and logvar.\n",
    "        recon_batch, y_pred, mu, logvar, z = model(data)\n",
    "        MSE_loss, KLD_loss, CE_loss = loss_function(recon_batch, data[:, 2:], mu, logvar, labels, y_pred, class_weights)\n",
    "        loss_train=MSE_loss+KLD_loss+CE_loss\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        MSE += MSE_loss.item()\n",
    "        KLD += KLD_loss.item()\n",
    "        CE += CE_loss.item()\n",
    "        train_loss += loss_train.item()\n",
    "        \n",
    "    average_train_MSE = MSE / len(train_loader.dataset)\n",
    "    average_train_KLD = KLD / len(train_loader.dataset)\n",
    "    average_train_CE = CE / len(train_loader.dataset)\n",
    "    average_train_loss = train_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return average_train_MSE, average_train_KLD, average_train_CE, average_train_loss\n",
    "        \n",
    "# Define testing function\n",
    "def test(test_loader, model, device):\n",
    "    MSE = 0\n",
    "    KLD = 0\n",
    "    CE = 0\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    all_labels = []  \n",
    "    all_preds_prob = [] \n",
    "    all_preds=[]\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            recon_batch, y_pred, mu, logvar, z = model(data)\n",
    "            MSE_loss, KLD_loss, CE_loss = loss_function(recon_batch, data[:, 2:], mu, logvar, labels, y_pred, class_weights)\n",
    "            loss_test=MSE_loss+KLD_loss+CE_loss\n",
    "            \n",
    "            MSE += MSE_loss.item()\n",
    "            KLD += KLD_loss.item()\n",
    "            CE += CE_loss.item()\n",
    "            test_loss += loss_test.item()\n",
    "            \n",
    "            y_pred_prob=torch.nn.functional.softmax(y_pred, dim=1).cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds_prob.extend(y_pred_prob) \n",
    "            all_preds.extend(torch.argmax(torch.tensor(y_pred_prob), dim=1).cpu().numpy())\n",
    "    \n",
    "    arr_all_labels=np.array(all_labels)\n",
    "    arr_all_labels_binarize=label_binarize(arr_all_labels, classes=[*range(3)])\n",
    "    arr_preds_prob=np.stack(all_preds_prob)\n",
    "    \n",
    "    average_MSE_test = MSE / len(test_loader.dataset)\n",
    "    average_KLD_test = KLD / len(test_loader.dataset)\n",
    "    average_CE_test = CE / len(test_loader.dataset)\n",
    "    average_test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "    mean_precision, mean_recall, mean_f1, mean_AUCPR= calculate_AUCPR(arr_all_labels_binarize, arr_preds_prob, n_classes=3)\n",
    "    mean_AUCROC = roc_auc_score(arr_all_labels, arr_preds_prob, multi_class='ovo', average='weighted')\n",
    "    return average_MSE_test, average_KLD_test, average_CE_test, average_test_loss,  mean_precision, mean_recall, mean_f1, mean_AUCPR, mean_AUCROC, all_labels, all_preds_prob, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "epoch_num=50\n",
    "batchsize_value=10\n",
    "# beta_value to weight between the KLD and the MSE LOSS\n",
    "beta_value=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data_final=pd.read_csv('./mock_data/mock_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X = mock_data_final.drop('outcome', axis=1)\n",
    "y = mock_data_final['outcome']\n",
    "object = MinMaxScaler()\n",
    "X_scaled=object.fit_transform(X.drop(['lat', 'lon'], axis=1))\n",
    "X_scaled=pd.DataFrame(X_scaled, columns=X.drop(columns=['lat','lon']).columns)\n",
    "\n",
    "\n",
    "X_coord=mock_data_final[['lat', 'lon']]\n",
    "X_scaled_coord = pd.concat([X_coord, X_scaled], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_coord, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train.values).float()\n",
    "X_test_tensor=torch.tensor(X_test.values).float()\n",
    "y_train_tensor = torch.tensor(y_train.values)\n",
    "y_test_tensor = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.long())  # .long() is used to convert the labels to integer\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor.long())\n",
    "class_weights = calculate_class_weights(y_train_tensor.long())\n",
    "class_weights=class_weights.to(device)\n",
    "# Create DataLoaders\n",
    "batch_size = batchsize_value\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model = SAVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: epoch 1 MSE: 2.0998, KLD: 0.0000, CE: 0.1196, loss: 2.2194\n",
      "test: epoch 1 MSE: 2.0189, KLD: 0.0000, CE: 0.1203, loss: 2.1392, AUCPR: 0.3324, AUCROC: 0.4673\n",
      "train: epoch 2 MSE: 2.0149, KLD: 0.0003, CE: 0.1210, loss: 2.1361\n",
      "test: epoch 2 MSE: 1.9176, KLD: 0.0008, CE: 0.1182, loss: 2.0366, AUCPR: 0.3188, AUCROC: 0.4761\n",
      "train: epoch 3 MSE: 1.8966, KLD: 0.0014, CE: 0.1139, loss: 2.0119\n",
      "test: epoch 3 MSE: 1.8035, KLD: 0.0019, CE: 0.1098, loss: 1.9152, AUCPR: 0.3681, AUCROC: 0.5130\n",
      "train: epoch 4 MSE: 1.8145, KLD: 0.0019, CE: 0.1131, loss: 1.9295\n",
      "test: epoch 4 MSE: 1.8047, KLD: 0.0023, CE: 0.1112, loss: 1.9182, AUCPR: 0.3476, AUCROC: 0.5086\n",
      "train: epoch 5 MSE: 1.6985, KLD: 0.0025, CE: 0.1097, loss: 1.8106\n",
      "test: epoch 5 MSE: 1.8665, KLD: 0.0030, CE: 0.1145, loss: 1.9840, AUCPR: 0.3340, AUCROC: 0.4702\n",
      "train: epoch 6 MSE: 1.5056, KLD: 0.0037, CE: 0.1087, loss: 1.6180\n",
      "test: epoch 6 MSE: 1.9365, KLD: 0.0037, CE: 0.1176, loss: 2.0578, AUCPR: 0.3132, AUCROC: 0.4714\n",
      "train: epoch 7 MSE: 1.3241, KLD: 0.0043, CE: 0.1132, loss: 1.4416\n",
      "test: epoch 7 MSE: 2.0167, KLD: 0.0047, CE: 0.1192, loss: 2.1406, AUCPR: 0.3207, AUCROC: 0.4808\n",
      "train: epoch 8 MSE: 1.1548, KLD: 0.0058, CE: 0.1131, loss: 1.2737\n",
      "test: epoch 8 MSE: 2.1000, KLD: 0.0050, CE: 0.1194, loss: 2.2244, AUCPR: 0.3376, AUCROC: 0.4980\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_MSE = []\n",
    "train_KLD = []\n",
    "train_CE = []\n",
    "train_losses=[]\n",
    "\n",
    "test_MSE = []\n",
    "test_KLD = []\n",
    "test_CE = []\n",
    "test_losses=[]\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience_limit = 5\n",
    "\n",
    "epochs = epoch_num\n",
    "for epoch in range(epoch_num):\n",
    "    average_train_MSE, average_train_KLD, average_train_CE, average_train_loss=train(train_loader, model, device=device)\n",
    "    average_MSE_test, average_KLD_test, average_CE_test, average_test_loss, mean_precision, mean_recall, mean_f1, mean_AUCPR, mean_AUCROC, all_labels, all_preds_prob, all_preds=test(test_loader, model, device=device)\n",
    "    print(f'train: epoch {epoch+1} MSE: {average_train_MSE:.4f}, KLD: {average_train_KLD:.4f}, CE: {average_train_CE:.4f}, loss: {average_train_loss:.4f}')\n",
    "    print(f'test: epoch {epoch+1} MSE: {average_MSE_test:.4f}, KLD: {average_KLD_test:.4f}, CE: {average_CE_test:.4f}, loss: {average_test_loss:.4f}, AUCPR: {mean_AUCPR:.4f}, AUCROC: {mean_AUCROC:.4f}')\n",
    "    \n",
    "    train_MSE.append(average_train_MSE)\n",
    "    train_KLD.append(average_train_KLD)\n",
    "    train_CE.append(average_train_CE)\n",
    "    test_MSE.append(average_MSE_test)\n",
    "    test_KLD.append(average_KLD_test)\n",
    "    test_CE.append(average_CE_test)\n",
    "    \n",
    "    train_losses.append(average_train_loss)\n",
    "    test_losses.append(average_test_loss)\n",
    "    \n",
    "    if average_CE_test < min_val_loss:\n",
    "        min_val_loss = average_CE_test\n",
    "        \n",
    "        # torch.save(model,'v2_best_savae_model.pth')\n",
    "        # torch.save(model.state_dict(), 'v2_best_savae_model_dict.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience_limit:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33253013367189826,\n",
       " 0.49944958781592447,\n",
       " 0.3992453996397909,\n",
       " 0.33756555894420065,\n",
       " 0.497961783008658)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision, mean_recall, mean_f1, mean_AUCPR, mean_AUCROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_ca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
